<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        scrapy爬虫进阶1：模拟登陆 - Smilettech&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i>  </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar">
            <img src="/img/1.png" />
        </div>
        <div class="name">
            <i>Yu</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#了解网站登录的原理"><span class="toc-text">了解网站登录的原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#用FormRequest模拟登录"><span class="toc-text">用FormRequest模拟登录</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#（1）构造FormRequest对象，即构造含有表单数据的请求"><span class="toc-text">（1）构造FormRequest对象，即构造含有表单数据的请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#（2）提交表单请求"><span class="toc-text">（2）提交表单请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#（3）设计Spider代码：爬取用户信息-实现登录"><span class="toc-text">（3）设计Spider代码：爬取用户信息,实现登录</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#识别验证码"><span class="toc-text">识别验证码</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>
        <div class="index-about-mobile">
            <i>  </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        scrapy爬虫进阶1：模拟登陆
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2018-03-19 20:36:15</span></span>

        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#爬虫" title="爬虫">爬虫</a>
        
        
        </span>
    </div>

    <div class="post-content no-indent">
        <p>　　有些网站需要用户登录之后才能爬取数据，此时scrapy爬虫需要先模拟用户登录。</p>
<h2 id="了解网站登录的原理"><a href="#了解网站登录的原理" class="headerlink" title="了解网站登录的原理"></a>了解网站登录的原理</h2><p>　　【请求】浏览器会向服务器发送<strong>含有登录表单数据</strong>的HTTP请求。具体来说：”表单”对应于HTML中的form节点，当用户填写完表单提交后，浏览器会根据form节点的内容发送请求。<strong>表单数据</strong>应包含的信息：账号 + 密码信息 + 3个隐藏信息(由多个键值对构成，每个键值对对应一个input元素，键→name,值→value)<br>　　　form节点的属性：①<strong>method</strong> 决定HTTP请求方法(一般是POST)<br>　　　　　　　　　　　②<strong>action</strong> 决定http请求的url<br>　　　　　　　　　　　③<strong>enctype</strong> 决定表单数据的编码类型<br>　　　form中的input节点属性：①<strong>email</strong>(账号) ②<strong>password</strong>(密码)<br>　　　　隐藏的input属性：在div style=”display:none;”中，比如①name=”_next”(登录成功后页面跳转的地址) ②name=”_formkey”(防止CSRF跨域攻击)<br>　　【响应】响应头部中Set-Cookie字段,就是服务器保存在浏览器的Cookie信息，其中包含标识用户身份的session信息，之后对该网站发送的其他HTTP请求都会带上这个“身份证”，服务器程序通过这个“身份证”识别出发送请求的用户，从而决定响应怎样的页面。</p>
<h2 id="用FormRequest模拟登录"><a href="#用FormRequest模拟登录" class="headerlink" title="用FormRequest模拟登录"></a>用FormRequest模拟登录</h2><h3 id="（1）构造FormRequest对象，即构造含有表单数据的请求"><a href="#（1）构造FormRequest对象，即构造含有表单数据的请求" class="headerlink" title="（1）构造FormRequest对象，即构造含有表单数据的请求"></a>（1）构造FormRequest对象，即构造含有表单数据的请求</h3><p>　　【方法1】直接构造FormRequest对象：先把表单信息收集到一个字典中，然后使用<strong>表单数据字典</strong>构造FormRequest对象。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;scrapy shell 登录url</span><br><span class="line">&gt;&gt;sel = response.xpath(&apos;//div[@style]/input&apos;)    #&lt;input&gt;中的信息(包含隐藏的)</span><br><span class="line">&gt;&gt;fd = dict(zip(sel.xpath(&apos;./@name&apos;).extract(),sel.xpath(&apos;./@value&apos;).extract())</span><br><span class="line">&gt;&gt;fd[&apos;email&apos;]=&apos;邮箱&apos;</span><br><span class="line">&gt;&gt;fd[&apos;password&apos;]=&apos;密码&apos;</span><br><span class="line">&gt;&gt;from scrapy.http import FormRequest</span><br><span class="line">&gt;&gt;request=FormRequest(&apos;登录url&apos;,formdata=fd)  #用formdata接受表单数据字典</span><br></pre></td></tr></table></figure></p>
<p>　　【方法2】FormRequest的<strong>from_response</strong>方法：参数是<strong>Response对象</strong>、账号和密码的表达数据字典，该方法能解析Rresponse对象的form节点,将隐藏在input中的信息自动填入表单数据。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;fd=&#123;&apos;email&apos;:&apos;邮箱&apos;,&apos;password&apos;:&apos;密码&apos;&#125;</span><br><span class="line">&gt;&gt;request=FormRequest.from_response(response,formdata=fd)</span><br></pre></td></tr></table></figure></p>
<h3 id="（2）提交表单请求"><a href="#（2）提交表单请求" class="headerlink" title="（2）提交表单请求"></a>（2）提交表单请求</h3><p>　　运行fetch(request)，得到log信息，可以看到POST请求的响应状态码为303，之后scrapy自动再发送一个GET请求(携带了第一个POST请求获取的Cookie信息)下载跳转页面，可以在浏览器中查看页面或者查看是否有特殊字符串,来验证登录是否成功。</p>
<h3 id="（3）设计Spider代码：爬取用户信息-实现登录"><a href="#（3）设计Spider代码：爬取用户信息-实现登录" class="headerlink" title="（3）设计Spider代码：爬取用户信息,实现登录"></a>（3）设计Spider代码：爬取用户信息,实现登录</h3><p>　　把模拟登录和爬取内容的代码分离开，使得逻辑上更加清晰<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">from scrapy.http import Request,FormRequest</span><br><span class="line">class LoginSpider(scrapy.Spider):</span><br><span class="line">    name = &apos;login&quot;</span><br><span class="line">    allowed_domains=[&apos;example.webscraping.com&apos;]</span><br><span class="line">    start_urls=[&apos;http:/....&apos;]</span><br><span class="line">    def parse(self,response):</span><br><span class="line">       #解析登录后下载的页面，此例中为用户个人信息页面</span><br><span class="line">        keys = response.css(&apos;table label::text&apos;).re(&apos;(.+):&apos;)</span><br><span class="line">        values-response.css(&apos;table td.w2p_fw::text&apos;).extract()</span><br><span class="line">        yield dict(zip(keys,values))</span><br><span class="line">    login_url=&apos;登录页面的url&apos;</span><br><span class="line">   #覆写基类的start_requests方法，最先请求登录页面</span><br><span class="line">    def start_requests(self):</span><br><span class="line">        yield Request(self.login_url,callback=self.login)</span><br><span class="line">    def login(self,response):     #登录页面的解析函数，在该方法中进行模拟登录，构造表单请求并提交</span><br><span class="line">        fd = &#123;&apos;email&apos;:&apos;邮箱&apos;,&apos;password&apos;:&apos;密码&apos;&#125;</span><br><span class="line">        yield FormRequest.from_response(response,formdata=fd,callback=self.parse_login)</span><br><span class="line">    def parse_login(self,response):      #登录成功后，处理响应</span><br><span class="line">        if &apos;Welcome Liu&apos; in response.text:     #页面是否有他是字符串</span><br><span class="line">            yield from super().start_requests()  #如果成功则调用基类的start_requests方法,继续爬取start_urls中的页面</span><br></pre></td></tr></table></figure></p>
<h2 id="识别验证码"><a href="#识别验证码" class="headerlink" title="识别验证码"></a>识别验证码</h2>
        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>
    </div>
</div>
    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = ""
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


</html>
